{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceptance of Personal Loan\n",
    "\n",
    "Excerpt From: Galit Shmueli. “Data Mining for Business Analytics.”\n",
    "\n",
    "Universal Bank is a relatively young bank that is growing rapidly in terms of overall customer acquisition. The majority of these customers are liability customers with varying sizes of relationship with the bank. The customer base of asset customers is quite small, and the bank is interested in growing this base rapidly to bring in more loan business. In particular, it wants to explore ways of converting its liability (deposit) customers to personal loan customers.\n",
    "\n",
    "A campaign the bank ran for liability customers showed a healthy conversion rate of over 9% successes. This has encouraged the retail marketing department to devise smarter campaigns with better target marketing. The goal of our analysis is to model the previous campaign’s customer behavior to analyze what combination of factors make a customer more likely to accept a personal loan. This will serve as the basis for the design of a new campaign.\n",
    "\n",
    "The bank’s dataset includes data on 5000 customers. The data include customer demographic information (age, income, etc.), customer response to the last personal loan campaign (Personal Loan), and the customer’s relationship with the bank (mortgage, securities account, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from dmba import classificationSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = pd.read_csv('data/UniversalBank.csv')\n",
    "bank_df.drop(columns=['ID', 'ZIP Code'], inplace=True)\n",
    "# split into training and validation\n",
    "X = bank_df.drop(columns=['Personal Loan'])\n",
    "y = bank_df['Personal Loan']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.40, \n",
    "                                                      random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9825)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1778   15\n",
      "     1   20  187\n"
     ]
    }
   ],
   "source": [
    "# single tree\n",
    "defaultTree = DecisionTreeClassifier(random_state=1)\n",
    "defaultTree.fit(X_train, y_train)\n",
    "classes = defaultTree.classes_\n",
    "classificationSummary(y_valid, defaultTree.predict(X_valid), class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9855)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1781   12\n",
      "     1   17  190\n"
     ]
    }
   ],
   "source": [
    "# bagging: (bootstrapping) vary the sample set each model is trained on \n",
    "bagging =BaggingClassifier(DecisionTreeClassifier(random_state=1), \n",
    "                            n_estimators=100, random_state=1)\n",
    "bagging.fit(X_train, y_train)\n",
    "classificationSummary(y_valid, bagging.predict(X_valid), class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9835)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1776   17\n",
      "     1   16  191\n"
     ]
    }
   ],
   "source": [
    "# boosting: AdaBoost: sequentially train and update the weights based on error\n",
    "boost = AdaBoostClassifier(DecisionTreeClassifier(random_state=1), \n",
    "                            n_estimators=100, random_state=1)\n",
    "boost.fit(X_train, y_train)\n",
    "classificationSummary(y_valid, boost.predict(X_valid), class_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9610)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1733   60\n",
      "     1   18  189\n"
     ]
    }
   ],
   "source": [
    "# Gradient boost: use residuals to fit the models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(max_depth=2, n_estimators=3,\n",
    "                                  learning_rate=1.0, random_state=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "classificationSummary(y_valid, gbrt.predict(X_valid), class_names=classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
